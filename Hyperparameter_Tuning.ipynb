{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482a8025",
   "metadata": {},
   "source": [
    "# Which Factors Influence the Price of Health Insurance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c233e5",
   "metadata": {},
   "source": [
    "You work as a Data Scientist for the New York Times. They are doing a story titled, \"Which Factors Influence the Price of Health Insurance?\". Many factors that affect how much you pay for health insurance are not within your control. Nonetheless, it's good to have an understanding of what they are. Hence, you have collected data about individuals for the new story. Your data contains basic factors about the\n",
    "\n",
    "Overall, I want to find how well the factors I collected can predict the individual insurance costs billed by the health insurance company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f0c1f",
   "metadata": {},
   "source": [
    "The first step of any machine learning project is to understand your data. The dataset contains the variables/features below. We should look at each feature to understand what type of feature it is, i.e., is it a categorical feature, binary, numeric, etc?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da5f5f6",
   "metadata": {},
   "source": [
    "This is what I will predict:\n",
    "\n",
    "charges: Individual medical costs billed by health insurance\n",
    "What type of item am I predicting? (e.g., categorical, numeric, binary, ordinal, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d25ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES\n",
    "\n",
    "# What is Machine Learning? f(x) = y\n",
    "\n",
    "# Features and Scikit-Learn\n",
    "\n",
    "## Methods of construction features\n",
    "\n",
    "### DictVectorizer (Tabular Data)\n",
    "\n",
    "### CountVectorizer (Text Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f24793d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = [] # Features go here\n",
    "y = [] # What you want to predict goes here\n",
    "with open('insurance.csv') as iFile:\n",
    "    iCSV = csv.reader(iFile, delimiter=',')\n",
    "    header = next(iCSV)\n",
    "    for row in iCSV:\n",
    "        item = {}\n",
    "        item['age'] = float(row[0])\n",
    "        item['sex'] = row[1]\n",
    "        item['bmi'] = float(row[2])\n",
    "        item['children'] = float(row[3])\n",
    "        item['smoker'] = row[4]\n",
    "        item['region'] = (row[5])\n",
    "        dataset.append(item)\n",
    "        y.append(float(row[6]))\n",
    "        \n",
    "# Here the lists are split into a 80% training portion and a 20% validation protion\n",
    "train_dataset, val_dataset, train_y, val_y = train_test_split(dataset, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# DictVectorizer will take a list of dictionaries and convert it into a matrix\n",
    "vec = DictVectorizer()\n",
    "\n",
    "train_matrix = vec.fit_transform(train_dataset) # .fit_transform() should only be applied to the training dataset\n",
    "val_matrix = vec.transform(val_dataset) # .transform() should only be aplied to the testing and validation datasets (validation in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71b5042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 19.0,\n",
       " 'sex': 'female',\n",
       " 'bmi': 27.9,\n",
       " 'children': 0.0,\n",
       " 'smoker': 'yes',\n",
       " 'region': 'southwest'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is what one dictionary looks like in the dataset\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb089ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'bmi', 'children', 'region=northeast', 'region=northwest', 'region=southeast', 'region=southwest', 'sex=female', 'sex=male', 'smoker=no', 'smoker=yes']\n"
     ]
    }
   ],
   "source": [
    "print(vec.feature_names_) # This list contains the feature names for each column in the feature matrix, i.e., age is the first column of train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def77354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46.   19.95  2.    0.    1.    0.    0.    1.    0.    1.    0.  ]\n",
      " [47.   24.32  0.    1.    0.    0.    0.    1.    0.    1.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.toarray()[0:2,:]) # This prints the first two rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de7b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Modify the weights below to achieve the LOWEST MSE as possible.\n",
    "weights = np.array([0., # 'age'\n",
    "                    0., # 'bmi'\n",
    "                    0., # 'children'\n",
    "                    0., # 'region=northeast'\n",
    "                    0., # 'region=northwest'\n",
    "                    0., # 'region=southeast'\n",
    "                    0., # 'region=southwest'\n",
    "                    0., # 'sex=female'\n",
    "                    0., # 'sex=male',\n",
    "                    0., # 'smoker=no'\n",
    "                    0.]) # 'smoker=yes' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9de33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 323425978.93488324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = val_matrix.dot(weights)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(val_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547ac822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 33596625.74155255\n"
     ]
    }
   ],
   "source": [
    "# Finding the weights manually is HARD.\n",
    "# Here we will use scikit-learn to find the weights for us. We are training a machine learning model!\n",
    "# Run the cells below to see how well it performs and what weights it finds.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf = LinearRegression(fit_intercept=False)\n",
    "\n",
    "clf.fit(train_matrix, train_y)\n",
    "\n",
    "lr_predictions = clf.predict(val_matrix)\n",
    "print(\"MSE:\", mean_squared_error(val_y, lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15bac88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Weights:\n",
      " 257.01791\n",
      "337.34778\n",
      "425.47128\n",
      "342.99371\n",
      "-27.60490\n",
      "-315.85397\n",
      "-467.22874\n",
      "-224.54077\n",
      "-243.15313\n",
      "-12059.18785\n",
      "11591.49395\n"
     ]
    }
   ],
   "source": [
    "print(\"LR Weights:\\n\", \"\\n\".join([f\"{x:.5f}\" for x in clf.coef_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c2d50",
   "metadata": {},
   "source": [
    "*****Note that a lower MSE means the model is better (i.e., your prediction is closer to the real amount), How\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f04f3",
   "metadata": {},
   "source": [
    "I suspect that the Linear Regression model is overfitting (e.g., weights are too large). Moreover, I think other models may provide better predictive ability. Choosing a model is only half the battle. In scikit-learn trying a different model is as simple as importing and using a different classifier object. But, to get the best performance from any given model, I need to tune all of the \"knobs\" availble within the model. I can find all the \"knobs\" a model contains by looking at the scikit learn documentation under the section \"Parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49297a3",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690014d9",
   "metadata": {},
   "source": [
    "I am going to experiment with the \"alpha\" parameter. The alpha parameter will control overfitting in the Ridge Regression model. I'll try the values 0, .00001, .0001, .001, .01, .1, 1, 10, 100 and find which value gives the best results. I should try this manually, by setting the alpha value to the different values and seeing the results. What do I find? Specifically, how does the alpha value impact the parameters? Also, what alpha gives the best performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59b92733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 35516055.0927728\n",
      "\n",
      "Ridge Weights:\n",
      " 262.40381\n",
      "331.86322\n",
      "325.48535\n",
      "173.70912\n",
      "-474.11913\n",
      "469.62882\n",
      "-707.97476\n",
      "-912.67017\n",
      "373.91421\n",
      "-11921.84742\n",
      "11383.09146\n"
     ]
    }
   ],
   "source": [
    "# Try the different alphas in this cell\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "clf = Ridge(alpha=0, fit_intercept=False)\n",
    "\n",
    "clf.fit(train_matrix, train_y)\n",
    "\n",
    "rr_predictions = clf.predict(val_matrix)\n",
    "print(\"MSE:\", mean_squared_error(val_y, rr_predictions))\n",
    "print(\"\\nRidge Weights:\\n\", \"\\n\".join([f\"{x:.5f}\" for x in clf.coef_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221fffd",
   "metadata": {},
   "source": [
    "\n",
    "Trying every hyper parameter one-by-one is time consuming. Instead, let us do it using GridSearchCV. Note that GridSearchCV will use cross-validation applied to the training dataset. So, the exact results may be different that what was found in the previous cell. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c009c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 35516054.80993609\n",
      "Best Alpha: 1e-05\n",
      "Cross-Validation Score: 38399017.57406919\n",
      "\n",
      "Ridge Weights:\n",
      " 262.40380\n",
      "331.86321\n",
      "325.48535\n",
      "173.70911\n",
      "-474.11912\n",
      "469.62880\n",
      "-707.97474\n",
      "-912.67014\n",
      "373.91420\n",
      "-11921.84709\n",
      "11383.09115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"alpha\": [0, .00001, .0001, .001, .01, .1, 1, 10, 100, 1000]}\n",
    "\n",
    "rr = Ridge(fit_intercept=False)\n",
    "\n",
    "clf = GridSearchCV(rr, param_grid=params, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "clf.fit(train_matrix, train_y)\n",
    "\n",
    "rr_predictions = clf.predict(val_matrix)\n",
    "print(\"MSE:\", mean_squared_error(val_y, rr_predictions))\n",
    "print(\"Best Alpha:\", clf.best_params_['alpha'])\n",
    "print(\"Cross-Validation Score:\", -clf.best_score_)\n",
    "print(\"\\nRidge Weights:\\n\", \"\\n\".join([f\"{x:.5f}\" for x in clf.best_estimator_.coef_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32479f3a",
   "metadata": {},
   "source": [
    "# Final Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da767960",
   "metadata": {},
   "source": [
    "\n",
    "So, where do you go from here? You can try different models such as:\n",
    "\n",
    "Lasso: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "ElasticNet: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "Random Forest Regression: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "SVM Regression: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "Each method has its own hyperparameters you must test to find what works best. Another option is to explore the use of \"Feature Engineering\". How will the model perform if you remove one or more features (columns)? What if you transform columns in some non-trival way, e.g., square the values in a column (e.g., age = age 2 ) or combine values via interaction terms (e.g., age*gender=Male). Overall, the combintions are endless. If you had access to the data at a specific company, then you could also try to collect more specific data, e.g., income, family history, etc. In the end, this is a creative endevor as much as it is a technical one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e09bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
